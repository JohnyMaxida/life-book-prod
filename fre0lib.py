# Freon Lib 1.2
import asyncio
import os, io, re
from pydub import AudioSegment
import speech_recognition as sr
import subprocess
import requests
from bs4 import BeautifulSoup
from telegram import Update
from telegram.ext import ContextTypes
# , , InputTextMessageContent, InlineQueryResultArticle
import mistune
import pdfplumber
import html
markdown = mistune.create_markdown()
DEVELOPERS = {"–î–∂–æ–Ω –¢–µ—Å–ª–∞": 1087968824, "–î–∂–æ–Ω –ú–∞–∫—Å–∏–¥–∞": 6794691889, "–ê–ª–∏—Å–∞ –¢–µ—Å–ª–∞": 7442136328}
LANG_CODE = "ru-RU" # –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—è –≥–æ–ª–æ—Å–∞ 6794691889
CHAT_ID = None
# sirius_n='https://t.me/siriusdetindigo'
# sirius_c='-1002261936806'
    
    
    
class MarkdownFormatter:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –≤ Markdown V2."""
    
    SPECIAL_CHARS = ['_', '*', '[', ']', '(', ')', '~', '`', '>', '#', '+', '-', '=', '|', '{', '}', '.', '!']
    
    @staticmethod
    def escape_markdown(text: str) -> str:
        """–≠–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤."""
        for char in MarkdownFormatter.SPECIAL_CHARS:
            text = text.replace(char, f'\\{char}')
        return text
    
    @staticmethod
    def format_code_block(lang: str, code: str) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –±–ª–æ–∫–∞ –∫–æ–¥–∞."""
        escaped_code = code.replace('`', '\\`')
        return f"```{lang}\n{escaped_code}\n```"
    
    @staticmethod
    def format_text(text: str) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—ã—á–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏."""
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∂–∏—Ä–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∏ –∫—É—Ä—Å–∏–≤–∞
        text = re.sub(r'\*\*(.+?)\*\*', lambda m: f"*{m.group(1)}*", text)
        text = re.sub(r'\*(.+?)\*', lambda m: f"_{m.group(1)}_", text)
        
        # –≠–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
        for char in ['[', ']', '~', '>', '#',  '|', '{', '}']:
            text = text.replace(char, f'\\{char}')
        return text

class MessageFormatter:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π."""
    
    @staticmethod
    def format_response(text: str) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∫–æ–¥–∞ –∏ Markdown."""
        parts = re.split(r'(```[\w]*\n.*?```)', text, flags=re.DOTALL)
        formatted_parts = []
        
        for part in parts:
            if not part.strip():
                continue
                
            if part.startswith('```') and part.endswith('```'):
                match = re.match(r'```(\w*)\n(.*?)```', part, re.DOTALL)
                if match:
                    lang, code = match.groups()
                    formatted_parts.append(MarkdownFormatter.format_code_block(lang, code))
            else:
                formatted_parts.append(MarkdownFormatter.format_text(part))
        
        return ''.join(formatted_parts)    
    

    
def Pic_Find(promt:str, KEYDRAW): 
    promts = promt.lower().split()
    new_prom = []
    EQ_DRAW = False
    for word in promts:
        flag = True
        for sord in KEYDRAW:
            if sord in word:
                EQ_DRAW = True
                flag = False
        if flag:
            new_prom.append(word)
    if EQ_DRAW:
        return new_prom
    else:
        return None  

    


# import requests
# from bs4 import BeautifulSoup

def parse_website(urls):
    documents = []
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –≤—Ö–æ–¥–Ω–æ–π –∞—Ä–≥—É–º–µ–Ω—Ç —Å—Ç—Ä–æ–∫–æ–π –∏–ª–∏ —Å–ø–∏—Å–∫–æ–º
    if isinstance(urls, str):
        urls = [urls]  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç—Ä–æ–∫—É –≤ —Å–ø–∏—Å–æ–∫
    
    for url in urls:
        try:
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º GET-–∑–∞–ø—Ä–æ—Å –∫ —Å–∞–π—Ç—É
            response = requests.get(url)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞ (–≤—ã–±—Ä–æ—Å–∏—Ç –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è 4xx/5xx –∫–æ–¥–æ–≤)
            response.raise_for_status()
            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç BeautifulSoup –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ HTML
            soup = BeautifulSoup(response.text, 'html.parser')
            # –ò—â–µ–º –≤—Å–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –±–ª–æ–∫–∏ –≤ —Ç–µ–≥–∞—Ö <p>
            text_blocks = soup.find_all('p')
            # –°–æ–±–∏—Ä–∞–µ–º –Ω–µ–ø—É—Å—Ç—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –±–ª–æ–∫–∏
            document = ' '.join(
                block.get_text(strip=True)
                for block in text_blocks
                if block.get_text(strip=True)
            )
            documents.append(document)
        except requests.exceptions.RequestException as e:
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ —Å–µ—Ç–∏/HTTP
            print(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è {url}: {str(e)}")
        except Exception as e:
            # –û–±—â–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥—Ä—É–≥–∏—Ö –∏—Å–∫–ª—é—á–µ–Ω–∏–π
            print(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –¥–ª—è {url}: {str(e)}")
    
    return documents

def Parse_Linx(text:str):
    print(f"Parse_Linx : Website")
    linx = contains_links(text)
    if linx:
        for link in linx:
            print(f"Link: {link}")            
        return linx[0] 
    else:
        return None
    
def Parse_TeLinx(text:str):
    print("Parse_Linx: Telegram")
    tlinx = contains_telegram_links(text)
    if tlinx:
        for chat_id, message_id in tlinx:
            print(f"Chat ID: {chat_id}, Message ID: {message_id}")            
        return tlinx[0]
    else:
        return None
  
  
      
def Parse_website_old(url):
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º GET-–∑–∞–ø—Ä–æ—Å –∫ —Å–∞–π—Ç—É
    response = requests.get(url)
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —É—Å–ø–µ—à–µ–Ω –ª–∏ –∑–∞–ø—Ä–æ—Å
    if response.status_code == 200:
        # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç BeautifulSoup –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ HTML
        soup = BeautifulSoup(response.text, 'html.parser')        
        # –ò—â–µ–º –≤—Å–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –±–ª–æ–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤ —Ç–µ–≥–∞—Ö <p>)
        text_blocks = soup.find_all('p')        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        documents_v2 = []
        for block in text_blocks:
            documents_v2.append(block.get_text(strip=True))
            # {
                # "data": {
                    # "text": block.get_text(strip=True)
                # }
            # })        
        return documents_v2
    else:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ: {response.status_code}")
        return []   
  
  
  
    
def contains_telegram_links(text):
    pattern = r"(?:https?://)?t\.me/(?:c/(-?\d+)|([\w_]+))/(\d+)"
    matches = re.findall(pattern, text)
    links_data = []
    for match in matches:
        if match[0]:  # –°—Å—ã–ª–∫–∞ —Å ID —á–∞—Ç–∞
            chat_id = f"-100{match[0]}"
        elif match[1]:  # –°—Å—ã–ª–∫–∞ —Å username
            chat_id = match[1]
        else:
            continue
        message_id = int(match[2])
        if has_non_digit(chat_id):
            chat_id = '@' + chat_id
        links_data.append((chat_id, message_id))
    if not links_data:
        print("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —Å—Å—ã–ª–∫–∏ –≤ —Ç–µ–∫—Å—Ç–µ.")
    return links_data
    
def has_non_digit(s):
    return any(not char.isdigit() for char in s)
    
def contains_links(text):
    # –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å—Å—ã–ª–æ–∫
    url_pattern = r'https?://[^\s]+'    
    # –ü–æ–∏—Å–∫ –≤—Å–µ—Ö —Å—Å—ã–ª–æ–∫ –≤ —Ç–µ–∫—Å—Ç–µ
    links = re.findall(url_pattern, text)    
    return links    
    
def extract_text_from_pdf(file_path):
    try:
        with pdfplumber.open(file_path) as pdf:
            text = ""
            for page in pdf.pages:
                text += page.extract_text() + "\n"
            return text.strip() if text else None
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF: {e}")
        return None  
   
def Find_User_Name(uid):
    if not isinstance(uid, int):
        uid = int(uid)
    for name, u_id in DEVELOPERS.items():
        if uid == u_id:
            return name
    return None  # Return None if user ID is not found in the dictionary
   
async def ALLOWED(context: ContextTypes.DEFAULT_TYPE):
    user_id = GetVar('user_id', context)
    print (f"ALLOWED > user_id = {user_id}")
    # update.effective_user.id
    # SetVar('user_id',USER_ID, context)
    dev_name = Find_User_Name(user_id)
    if dev_name:
        print (f">{dev_name} > –î–û–°–¢–£–ü –û–î–û–ë–†–ï–ù")
        return True  
    else:       
        await SEX("‚ùå –£ –í–∞—Å –Ω–µ—Ç –ø—Ä–∞–≤ üôÖüèº –ú–æ–¥–µ—Ä–∞—Ç–æ—Ä–∞ ü¶πüèº –¥–ª—è —ç—Ç–æ–π –∫–æ–º–∞–Ω–¥—ã", context)
        return False 
   
# def Upmodel(mod_id, context: ContextTypes.DEFAULT_TYPE):
    # global CHAT_ID
    # CHAT_ID = user_id
    # SetVar('last_mod', mod_id, context)    
     

def Upchate(user_id, context: ContextTypes.DEFAULT_TYPE):
    global CHAT_ID
    CHAT_ID = user_id
    SetVar('last_chat', user_id, context)

# def Gemodel(context: ContextTypes.DEFAULT_TYPE):
    # return CHAT_ID
    # return GetVar('last_mod', context) 

    
def Gechate(context: ContextTypes.DEFAULT_TYPE):
    chid = GetVar('last_chat', context)
    # CHAT_ID = chid if chid else CHAT_ID
    return chid if chid else CHAT_ID
    # return GetVar('last_chat', context)        

def ASPLIT(text, max_length=4096):
    chunks = []
    while len(text) > max_length:
        # Try to split at newline or space
        split_index = text.rfind('\n', 0, max_length)
        if split_index == -1:
            split_index = text.rfind(' ', 0, max_length)        
        if split_index == -1:
            split_index = max_length        
        chunks.append(text[:split_index])
        text = text[split_index:].lstrip()    
    if text:
        chunks.append(text)    
    return chunks    
    
    
async def ASPLITTER(response:str, context: ContextTypes.DEFAULT_TYPE):
    parts = response.split('```')    
    for index, part in enumerate(parts):
        part = part.strip()        
        if index % 2 == 1:  # Code block
            code_chunks = ASPLIT(f"```{part}```")
            for chunk in code_chunks:
                print ('> –ß–ê–ù–ö–ò –ö–û–î–ê: =====')
                await ZEX(chunk, context)
                await asyncio.sleep(2)
        else:  # Regular text
            text_chunks = ASPLIT(part)
            for chunk in text_chunks:
                print ('> –ß–ê–ù–ö–ò –¢–ï–ö–°–¢–ê: =====')
                # if is_mark2(chunk):
                    # print ("–ù–∞–π–¥–µ–Ω –ú–î2 - pass")
                    ## formad = MarkdownFormatter.format_text(chunk)
                    # formad = ESUm2(chunk)                    
                    # await ZEY(formad, context)
                # el
                # if is_markdown_format(chunk):
                    # print ("–ù–∞–π–¥–µ–Ω –ú–î (1 –∏–ª–∏ 2)")                    
                print ("force format_to_md...") 
                formad = format_to_md(chunk)
                await ZEX(formad, context)
                # else:                     
                    # formad = clearq(chunk) 
                    # await ZEX(chunk, context)
                await asyncio.sleep(2)

def clearq(text):
    return text.replace('&quot;','"')

def TuneOGGpath(user_name):
    k = 1  # –õ–æ–∫–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è —Å—á—ë—Ç—á–∏–∫–∞ —Ñ–∞–π–ª–æ–≤
    user_path = os.path.join(os.getcwd(), 'data-ogg')  # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤
        # user_path = './data-ogg/'  # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤
    os.makedirs(user_path, exist_ok=True)  # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–∫–∏, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    while True:
        file_name = f"{user_name}_{k}.ogg"  # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        full_path = os.path.join(user_path, file_name)  # –ü–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
        if not os.path.isfile(full_path):  # –ü—Ä–æ–≤–µ—Ä–∫–∞, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª
            return full_path  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Ç—å, –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        k += 1  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫, –µ—Å–ª–∏ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç

async def Transcribe_audio(user_name: str, file_id: str, context) -> str:
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—É—Ç–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è OGG-—Ñ–∞–π–ª–∞
    # user_path = './data-ogg/'
    # os.makedirs(user_path, exist_ok=True)  # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–∫–∏, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    # file_name = f"{user_name}_TEMP.ogg"
    # ogg_file_path = os.path.join(user_path, file_name)
    # wav_file_path = ogg_file_path.replace(".ogg", ".wav")
    ogg_file_path = TuneOGGpath(user_name)
    print("OGGPath > ", ogg_file_path)
    # print("WavPath > ", wav_file_path)
    # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
    try:
        file = await context.bot.get_file(file_id)
        await file.download_to_drive(ogg_file_path)
    except Exception as e:
        return f"err: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ –∞—É–¥–∏–æ: {e}"
# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è OGG –≤ WAV —Å –ø–æ–º–æ—â—å—é FFmpeg
    # try:
        # subprocess.run(
            # ["ffmpeg", "-i", ogg_file_path, wav_file_path],
            # check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE
        # )
    # except subprocess.CalledProcessError as e:
        # return f"err: –û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ OGG –≤ WAV: {e.stderr.decode()}"
    # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ WAV
    # try:
        # recognizer = sr.Recognizer()
        # with sr.AudioFile(wav_file_path) as source:    
# –ß—Ç–µ–Ω–∏–µ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ñ–∞–π–ª–∞
    try:    
        with open(ogg_file_path, 'rb') as f:
            voice_data = io.BytesIO(f.read())        
        audio = AudioSegment.from_ogg(voice_data)
        audio_data = io.BytesIO()
        audio.export(audio_data, format="wav")
        audio_data.seek(0)
    except Exception as e:
        return f"err: –û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∞—É–¥–∏–æ: {e}"
    with sr.AudioFile(audio_data) as source:
        recognizer = sr.Recognizer()
        audio_data = recognizer.record(source)
        try:
            text = recognizer.recognize_google(audio_data, language=LANG_CODE)
            return text
        except sr.UnknownValueError:
            return(f"err: –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—è Google Speech Recognition")
        except sr.RequestError as e:
            return(f"err: –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—è Google Speech Recognition: {e}")    
        finally:
            # –£–¥–∞–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            if os.path.exists(ogg_file_path):
                os.remove(ogg_file_path)
            # if os.path.exists(wav_file_path):
                # os.remove(wav_file_path)

# Markdown and Text Formatting Utilities
# def Ma2Htm(text): 
    # text = "# –ó–∞–≥–æ–ª–æ–≤–æ–∫\n\n–≠—Ç–æ **–∂–∏—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç**."
    # html = markdown(text)
    # print(html)
    # return html
    
# def formakdown(text):    
    # text = text.replace('**', '*') # Replace ** with * for bold
    # return text


def is_mark2(text):
    return bool('**' in text)


def is_markdown_format(text):
    patterns = [        
        r'\*[^*\n]+\*',      # –ü—Ä–æ–≤–µ—Ä–∫–∞ *–æ–¥–∏–Ω–∞—Ä–Ω—ã–º–∏* –∑–≤–µ–∑–¥–æ—á–∫–∞–º–∏
        r'\*\*[^*\n]+\*\*',  # –ü—Ä–æ–≤–µ—Ä–∫–∞ **–î–∞–±–ª** –∑–≤–µ–∑–¥–æ—á–∫–∞–º–∏
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        r'^\*[^*\n]+\*$',  # –ó–∞–≥–æ–ª–æ–≤–æ–∫ 1 —É—Ä–æ–≤–Ω—è
        r'^`[^`\n]+`$',    # –ó–∞–≥–æ–ª–æ–≤–æ–∫ 2 —É—Ä–æ–≤–Ω—è
        r'^_[^_\n]+_$',    # –ó–∞–≥–æ–ª–æ–≤–æ–∫ 3 —É—Ä–æ–≤–Ω—è
        r'^# ',              # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å #
        r'^## ',             # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å ##
        r'^### ',            # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å ###
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–ø–∏—Å–∫–æ–≤
        r'^\‚Ä¢ .+'
    ]    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ–≥–æ –∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    has_markdown_elements = False
    for pattern in patterns:
        if re.search(pattern, text, re.MULTILINE):
            has_markdown_elements = True
            break    
    return has_markdown_elements


# def format_for_telegram(text):
    # return text.strip()

    
# –í –ø—Ä–æ—à–ª–æ–º –∑–∞–ø—Ä–æ—Å–µ —è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª –∑–Ω–∞—á–µ–Ω–∏–µ `max_tokens` —Ä–∞–≤–Ω–æ–µ 1024\.
def ESUm1(text): # Debug special characters '_', '*','`',
    # print ('ESUm1 –≤—Ö–æ–¥: ', text, end='') 
    if text.startswith('```'):
        print (' –æ–±–Ω–∞—Ä—É–∂–µ–Ω –ö–æ–¥!', text)
        return text    
    text = text.replace('&amp;quot;','*')        
    special_chars = ['_', '*', '`']
    for char in special_chars:
        count = text.count(char)
        if count>0 and (count % 2 != 0):
            text += char 
    return text
    # print (' –≤—ã—Ö–æ–¥: ', text)            
    
    
    
    
    
    
    
def ESUm2(text): # Escape special characters EX: '_', '*','`',
    print ('ESUm2 –≤—Ö–æ–¥: ', text)
    escape_chars = ['[', ']', '(', ')', '~', '>', '#', '+', '-', '=', '|', '{', '}', '.', '!']
    text = str(text)
    for char in escape_chars:
        text = text.replace(char, '\\' + char)   
    print ('ESUm2 –≤—ã—Ö–æ–¥: ', text)
    return text    
    
    


def format_to_md(input_text):
    # –î–µ–∫–æ–¥–∏—Ä—É–µ–º HTML-—Å—É—â–Ω–æ—Å—Ç–∏ –≤ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
    decoded_text = html.unescape(input_text)
    
    # –ó–∞–º–µ–Ω—è–µ–º –¥–≤–æ–π–Ω—ã–µ –∑–≤–µ–∑–¥–æ—á–∫–∏ –Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å–∏–º–≤–æ–ª
    formatted_text = decoded_text.replace('**', '~~')
    
    # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —Å—Ç—Ä–æ–∫–∏
    lines = formatted_text.split('\n')    
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é —Å—Ç—Ä–æ–∫—É
    formatted_lines = []
    for line in lines:
        # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –æ–¥–∏–Ω–æ—á–Ω–æ–π –∑–≤–µ–∑–¥–æ—á–∫–∏, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –µ—ë –≤ –ø—É–Ω–∫—Ç
        if line.lstrip().startswith('*') and not line.lstrip().endswith('*'):
            indent = '    ' * (len(line) - len(line.lstrip()))  # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Ç—Å—Ç—É–ø
            content = line.lstrip()[1:].strip()  # –£–±–∏—Ä–∞–µ–º –∑–≤–µ–∑–¥–æ—á–∫—É –∏ –ø—Ä–æ–±–µ–ª—ã
            formatted_lines.append(f"{indent}- {content}")
        else:
            formatted_lines.append(line) 
    # –°–æ–µ–¥–∏–Ω—è–µ–º —Å—Ç—Ä–æ–∫–∏ –æ–±—Ä–∞—Ç–Ω–æ
    formatted_text = '\n'.join(formatted_lines) 
    # –ó–∞–º–µ–Ω—è–µ–º –∑–≤–µ–∑–¥–æ—á–∫–∏ –Ω–∞ –∫—É—Ä—Å–∏–≤–Ω—ã–π —Å–∏–º–≤–æ–ª
    formatted_text = formatted_text.replace('*', '_') 
    # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∂–∏—Ä–Ω—ã–π —Å—Ç–∏–ª—å
    formatted_text = formatted_text.replace('~~', '*') 
    return formatted_text 
    

    
def GetVar(variable:str, context: ContextTypes.DEFAULT_TYPE):   
    return context.user_data.get(variable)
    
def GetVAR(variable:str, defvalue, context: ContextTypes.DEFAULT_TYPE): 
    return context.user_data.get(variable, defvalue)
    
def SetVar(variable:str, value, context: ContextTypes.DEFAULT_TYPE):  
    context.user_data[variable] = value
    
def replace_emojis(text, new_emoji):
    # –ó–∞–º–µ–Ω–∞ —Å–º–∞–π–ª–æ–≤ –Ω–∞ –Ω–æ–≤—ã–π —Å–º–∞–π–ª, –∏—Å–ø–æ–ª—å–∑—É—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å–ø–∏—Å–∫–∞
    replaced_text = ''.join([new_emoji if emoji.is_emoji(char) else char for char in text])
    return replaced_text  



async def UMR(text:str, update: Update):
    return await update.message.reply_text(text)     
    
async def ZEX(text: str, context: ContextTypes.DEFAULT_TYPE, chat_id: int = None, reply_markup = None): 
    print ('ZEX –¥–æ: ', text)
    text = ESUm1(text)
    print ('ZEX ESUm1: ', text)
    try: # 
        res = await SEX(text, context, chat_id=chat_id, parse_mode='Markdown', reply_markup=reply_markup)
    except Exception as e:
        print(f"ZEX: –û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞: {e}")     
        error = "–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ X-Markdown"
        # res = await SEX(error, context, chat_id=chat_id)        
        res = await SEX(text, context, chat_id=chat_id, parse_mode=None, reply_markup=reply_markup)    
    await asyncio.sleep(1)
    return res     
    
async def ZEY(text: str, context: ContextTypes.DEFAULT_TYPE, chat_id: int = None, reply_markup = None): 
    print ('ZEY –¥–æ: ', text)
    # text = ESUm2(text)
    # print ('ZEY ESUm1: ', text)
    try: # 
        res = await SEX(text, context, chat_id=chat_id, parse_mode='MarkdownV2', reply_markup=reply_markup)
    except Exception as e:
        print(f"ZEY: –û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞: {e}")     
        error = "–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ Y, –±—É–¥–µ—Ç –≤—ã–¥–∞–Ω –Ω–µ—Ñ–æ—Ä–º–∞—Ç"
        return None
        # await SEX(error, context, chat_id=chat_id)
        # res  = await SEX(text, context, chat_id=chat_id, parse_mode=None, reply_markup=reply_markup)    
    return res        

async def SEX(text: str, context: ContextTypes.DEFAULT_TYPE, chat_id: int = None, parse_mode = None, reply_markup = None):
    text = clearq(text)
    if chat_id is None:
        chat_id = Gechate(context)
    params = {      # params["chat_id"] = chat_id
        "text": text,
        "chat_id": chat_id, }
    if reply_markup is not None:
        params["reply_markup"] = reply_markup    
    if parse_mode is not None:
        params["parse_mode"] = parse_mode  
    print ('SEX: ', text)    
    return await context.bot.send_message(**params) 
    

async def SEFoB(chat_id, picfile, cap_text:str, context: ContextTypes.DEFAULT_TYPE):  
    cap_text = ESUm1(cap_text)  
    print ('SEFoB –æ—Ç–ª–∞–¥–∫–∞: ', cap_text)    
    if os.path.isfile(picfile):  # , parse_mode='Markdown'
        print ("SEFoB: Photo found, sending photo block")
        with open(picfile, 'rb') as photo:
            await context.bot.send_photo(chat_id=chat_id, photo=photo, caption=cap_text, parse_mode='Markdown') 
    else:
        print ("SEFoB: Photo not found, sending text")
        await context.bot.send_message(chat_id=chat_id, text=cap_text, parse_mode='Markdown') 


  
    
    
 
    


# –ü–æ–ª—É—á–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
# M_LAMA_b = os.getenv('M_LAMA_b', '–ù–ï–¢')
# M_GEMA_2b = os.getenv('M_GEMA_2b', '–ù–ï–¢')
# M_QUIN_b5 = os.getenv('M_QUIN_b5', '–ù–ï–¢')
# M_QUIN_3b = os.getenv('M_QUIN_3b', '–ù–ï–¢')
# M_DSC2I_16b = os.getenv('M_DSC2I_16b', '–ù–ï–¢')
# M_AYA_8b = os.getenv('M_AYA_8b', '–ù–ï–¢')
# M_SCI_3b = os.getenv('M_SCI_3b', '–ù–ï–¢')
# MODELS = [M_QUIN_b5, M_LAMA_b, M_GEMA_2b, M_QUIN_3b, M_SCI_3b, M_AYA_8b, M_DSC2I_16b]   

# """
# async def ai_process(context, query):    
    # paging = 4096
    # yot = '<|eot_id|>'
    # accumulated_text = ""    
    # –ù–∞—á–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å –∫ –º–æ–¥–µ–ª–∏    
    # response = ai_query(query)
    # if not response:
        # await SEX("–£–ü–°, –Ω–µ —Å–º–æ–≥ –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏...", context)
        # return    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞
    # while not response.endswith(yot):  # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à —Ç–æ–∫–µ–Ω –∫–æ–Ω—Ü–∞
        # additional_response = ai_query(query)
        # response += additional_response
    # –†–∞–∑–¥–µ–ª—è–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏ –ø–æ –∫–æ–¥—É
    # parts = response.split('```')  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç—Ä–æ–π–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ –∫–∞–∫ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
    # for index, part in enumerate(parts):
        # part = part.strip()  # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã 
        # –ï—Å–ª–∏ —ç—Ç–æ –∫–æ–¥ –∏ –º—ã –Ω–µ –Ω–∞ –ø–µ—Ä–≤–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Ç–µ–∫—Å—Ç
        # if index % 2 == 1:  # –ö–æ–¥ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –Ω–∞ –Ω–µ—á–µ—Ç–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–∞—Ö
            # if accumulated_text:
                # await SEX(cleb(accumulated_text), context)
                # accumulated_text = ""
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–æ–¥ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –±–ª–æ–∫–µ
            # await ZEX(f"```{cleb(part)}```", context)
        # else:
            # accumulated_text += part + "\n"  # –ù–∞–∫–æ–ø–ª–µ–Ω–∏–µ –æ–±—ã—á–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å–ª–∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –ø—Ä–µ–≤—ã—à–∞–µ—Ç 4096 —Å–∏–º–≤–æ–ª–æ–≤
        # while len(accumulated_text) > paging:
            # await SEX(cleb(accumulated_text[:paging]), context)
            # accumulated_text = accumulated_text[paging:]
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–π—Å—è —Ç–µ–∫—Å—Ç, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
    # if accumulated_text:
        # await SEX(cleb(accumulated_text), context)
    # return accumulated_text
# """        